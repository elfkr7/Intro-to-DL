{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron_HW1_Elif_KIR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBxBUJKMFv0GKWtgv2EMIJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elfkr7/Intro-to-DL/blob/main/Perceptron_HW1_Elif_KIR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 8 is at the bottom."
      ],
      "metadata": {
        "id": "17DAjawxJOit"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u04namr4TixD",
        "outputId": "cb614486-4475-449f-8226-70d4d657f12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n"
          ]
        }
      ],
      "source": [
        "#Import the Data\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "\n",
        "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "fileobj = urllib.request.urlopen(url)\n",
        "\n",
        "print('Downloading...')\n",
        "with tarfile.open(fileobj=fileobj, mode=\"r|gz\") as tar:\n",
        "    tar.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WJRfM-b331b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Data preprocessing.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def load_pickle(f: str) -> Any:\n",
        "    \"\"\"Load a pickle file.\n",
        "\n",
        "    Parameters:\n",
        "        f: the pickle filename\n",
        "\n",
        "    Returns:\n",
        "        the pickled data\n",
        "    \"\"\"\n",
        "    return pickle.load(f, encoding=\"latin1\")\n",
        "\n",
        "\n",
        "def load_CIFAR_batch(filename: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Load a single batch of cifar data.\n",
        "\n",
        "    Parameters:\n",
        "        filename: the pickle filename\n",
        "\n",
        "    Returns:\n",
        "        the data\n",
        "        the labels\n",
        "    \"\"\"\n",
        "    with open(filename, \"rb\") as f:\n",
        "        datadict = load_pickle(f)\n",
        "        X = datadict[\"data\"]\n",
        "        Y = datadict[\"labels\"]\n",
        "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
        "        Y = np.array(Y)\n",
        "        return X, Y\n",
        "\n",
        "\n",
        "def load_CIFAR10(ROOT: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"Load all of cifar data.\n",
        "\n",
        "    Parameters:\n",
        "        ROOT: the root directory containing the data\n",
        "\n",
        "    Returns:\n",
        "        training data\n",
        "        training labels\n",
        "        testing data\n",
        "        testing labels\n",
        "    \"\"\"\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for b in range(1, 6):\n",
        "        f = os.path.join(ROOT, \"data_batch_{}\".format(b))\n",
        "        X, Y = load_CIFAR_batch(f)\n",
        "        xs.append(X)\n",
        "        ys.append(Y)\n",
        "    Xtr = np.concatenate(xs)\n",
        "    Ytr = np.concatenate(ys)\n",
        "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, \"test_batch\"))\n",
        "    return Xtr, Ytr, Xte, Yte\n",
        "\n",
        "\n",
        "def get_CIFAR10_data(\n",
        "    num_training: int = 49000,\n",
        "    num_validation: int = 1000,\n",
        "    num_test: int = 10000,\n",
        "    subtract_mean: bool = True,\n",
        "):\n",
        "    \"\"\"Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for classifiers. These are the same steps as we used for the SVM, but\n",
        "    condensed to a single function.\n",
        "\n",
        "    Parameters:\n",
        "        num_training: number of training images\n",
        "        num_validation: number of validation images\n",
        "        num_test: number of test images\n",
        "        subtract_mean: whether or not to normalize the data\n",
        "\n",
        "    Returns:\n",
        "        the train/val/test data and labels\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    cifar10_dir = os.path.join(\"cifar-10-batches-py\")\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "    # Subsample the data\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean image\n",
        "    if subtract_mean:\n",
        "        mean_image = np.mean(X_train, axis=0)\n",
        "        X_train -= mean_image\n",
        "        X_val -= mean_image\n",
        "        X_test -= mean_image\n",
        "\n",
        "    # Transpose so that channels come first\n",
        "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
        "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
        "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
        "\n",
        "    # Package data into a dictionary\n",
        "    return {\n",
        "        \"X_train\": X_train,\n",
        "        \"y_train\": y_train,\n",
        "        \"X_val\": X_val,\n",
        "        \"y_val\": y_val,\n",
        "        \"X_test\": X_test,\n",
        "        \"y_test\": y_test,\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "zmBhirHRaCC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Utility functions for saving predictions for submission.\"\"\"\n",
        "\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def write_csv(file_path: str, y_list: np.ndarray):\n",
        "    \"\"\"Write a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "        file_path: name of the file to save\n",
        "        y_list: y predictions\n",
        "    \"\"\"\n",
        "    solution_rows = [(\"id\", \"category\")] + [(i, y) for (i, y) in enumerate(y_list)]\n",
        "    with open(file_path, \"w\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(solution_rows)\n",
        "\n",
        "\n",
        "def output_submission_csv(output_file_path: str, y_test: np.ndarray):\n",
        "    \"\"\"Save predictions.\n",
        "\n",
        "    Parameters:\n",
        "        output_file_path: name of the file to save\n",
        "        y_test: y predictions\n",
        "    \"\"\"\n",
        "    write_csv(output_file_path, y_test)\n"
      ],
      "metadata": {
        "id": "AbP17xrhg2fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries\n",
        "import random\n",
        "import numpy as np\n",
        "#from data_process import get_CIFAR10_data\n",
        "from scipy.spatial import distance\n",
        "%matplotlib inline\n",
        "from save_submission import output_submission_csv"
      ],
      "metadata": {
        "id": "3-sxc4x1aKr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can change these numbers for experimentation\n",
        "# For submission we will use the default values \n",
        "TRAIN_IMAGES = 40000\n",
        "VAL_IMAGES = 10000"
      ],
      "metadata": {
        "id": "g3feCE2UaKuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data\n",
        "data = get_CIFAR10_data(TRAIN_IMAGES, VAL_IMAGES)\n",
        "X_train_CIFAR, y_train_CIFAR = data['X_train'], data['y_train']\n",
        "X_val_CIFAR, y_val_CIFAR = data['X_val'], data['y_val']\n",
        "X_test_CIFAR, y_test_CIFAR = data['X_test'], data['y_test']\n",
        "n_class_CIFAR = len(np.unique(y_test_CIFAR))"
      ],
      "metadata": {
        "id": "mYC5MTxhb54q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape the data\n",
        "X_train_CIFAR = np.reshape(X_train_CIFAR, (X_train_CIFAR.shape[0], -1))\n",
        "X_val_CIFAR = np.reshape(X_val_CIFAR, (X_val_CIFAR.shape[0], -1))\n",
        "X_test_CIFAR = np.reshape(X_test_CIFAR, (X_test_CIFAR.shape[0], -1))\n"
      ],
      "metadata": {
        "id": "reHBdnLLb56m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perceptron\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, n_class: int, lr: float, epochs: int):\n",
        "        \"\"\"Initialize a new classifier.\n",
        "        Parameters:\n",
        "            n_class: the number of classes\n",
        "            lr: the learning rate\n",
        "            epochs: the number of epochs to train for\n",
        "        \"\"\"\n",
        "        self.w = np.random.randn() #np.randn(3073,1) ###### TODO: change this\n",
        "        self.lr = lr #0.1 ###### TODO: change this\n",
        "        self.epochs = epochs #10 ###### TODO: change this\n",
        "        self.n_class = n_class #10 ###### TODO: change this\n",
        "\n",
        "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
        "        \"\"\"Train the classifier.\n",
        "        Use the perceptron update rule as introduced in Lecture 3.\n",
        "        Parameters:\n",
        "            X_train: a number array of shape (N, D) containing training data;\n",
        "                N examples with D dimensions\n",
        "            y_train: a numpy array of shape (N,) containing training labels\n",
        "        \"\"\"\n",
        "        N, D = X_train.shape\n",
        "        self.w = np.random.randn(self.n_class, D+1) #+1 for bias term \n",
        "        X_train_stacked = np.hstack((np.ones((N,1)),X_train)) #add one more dimension with full of ones\n",
        "\n",
        "        ###### YOUR CODE STARTS HERE ######\n",
        "        \n",
        "        for  epochs in range(self.epochs):\n",
        "          for p in range(N):\n",
        "            y_hat= np.dot(self.w,X_train_stacked[p])\n",
        "            y_predicted = np.argmax(y_hat, axis=0)\n",
        "            y_= y_train[p]\n",
        "            if y_!=y_predicted:\n",
        "              self.w[y_]= self.w[y_] + self.lr*X_train_stacked[p]\n",
        "              self.w[y_predicted]= self.w[y_predicted] - self.lr*X_train_stacked[p]\n",
        "          return(self.w)\n",
        "          \n",
        "         \n",
        "        ###### YOUR CODE ENDS HERE ######\n",
        "        pass\n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Use the trained weights to predict labels for test data points.\n",
        "        Parameters:\n",
        "            X_test: a numpy array of shape (N, D) containing testing data;\n",
        "                N examples with D dimensions\n",
        "        Returns:\n",
        "            predicted labels for the data in X_test; a 1-dimensional array of\n",
        "                length N, where each element is an integer giving the predicted\n",
        "                class.\n",
        "        \"\"\"\n",
        "        N, D = X_test.shape\n",
        "        y_test = np.zeros(N)\n",
        "        ###### YOUR CODE STARTS HERE ######\n",
        "        X_test_stacked = np.hstack((np.ones((N,1)),X_test)) #add one more dimension with full of ones\n",
        "        y_hat= np.dot(self.w,X_test_stacked.T)\n",
        "        y_test = np.argmax(y_hat, axis=0)\n",
        "        ###### YOUR CODE ENDS HERE ######\n",
        "        return y_test"
      ],
      "metadata": {
        "id": "mBHKb8sNb5-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.5\n",
        "n_epochs = 100\n",
        "\n",
        "percept_CIFAR = Perceptron(n_class_CIFAR, lr, n_epochs)\n",
        "percept_CIFAR.train(X_train_CIFAR, y_train_CIFAR)"
      ],
      "metadata": {
        "id": "0uRSFm2-b6Li",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a0d661-4938-430f-ada0-291a42338f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -137.30911201,  -433.34284684,  -683.15698744, ...,\n",
              "         -617.08529548,  -571.13941257,  -821.7322969 ],\n",
              "       [ -215.38847499,    -8.27020756,  -613.25551652, ...,\n",
              "          527.52254446,    86.35963885,  -704.75568502],\n",
              "       [  257.99082957,  -419.71854385,   359.00074472, ...,\n",
              "          158.53983639,  -678.62210951,  -547.72704706],\n",
              "       ...,\n",
              "       [  116.57429984,   840.90045583,   477.25999209, ...,\n",
              "         -988.92182895,  -523.14521413,   217.6397778 ],\n",
              "       [ -222.15332887,   451.6401134 ,   216.61261532, ...,\n",
              "          530.21019269,  1273.93712702,  1074.7207764 ],\n",
              "       [ -178.20027177,  -470.48329638, -1016.11573732, ...,\n",
              "          379.68067071,   955.42267019,  1524.35104656]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get accuracy \n",
        "def get_acc(pred, y_test):\n",
        "  return np.sum(y_test==pred)/len(y_test)*100"
      ],
      "metadata": {
        "id": "pyr32TFQDKD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_percept = percept_CIFAR.predict(X_train_CIFAR)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_CIFAR)))"
      ],
      "metadata": {
        "id": "AuD9j4sMb6OH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ea091c-26b0-4731-9326-0c67dcd43844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 30.442500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_percept = percept_CIFAR.predict(X_val_CIFAR)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_CIFAR)))"
      ],
      "metadata": {
        "id": "TsDm2Llkb6QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39eca849-6c47-4372-ac60-282e36eabf3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 28.140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_percept = percept_CIFAR.predict(X_test_CIFAR)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_CIFAR)))"
      ],
      "metadata": {
        "id": "-Pq7xVpRb6Tf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f741e1-1f25-4f44-aa66-124321f7e099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 28.160000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_submission_csv('Perceptron_submission_CIFAR.csv', percept_CIFAR.predict(X_test_CIFAR))"
      ],
      "metadata": {
        "id": "8OwBjM-yNatr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic\n",
        "\n",
        "\"\"\"Logistic regression model.\"\"\"\n",
        "from numpy.lib.arraysetops import unique\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class Logistic:\n",
        "    def __init__(self, lr: float, epochs: int):\n",
        "        \"\"\"Initialize a new classifier.\n",
        "        Parameters:\n",
        "            lr: the learning rate\n",
        "            epochs: the number of epochs to train for\n",
        "        \"\"\"\n",
        "        self.w = np.random.randn() ###### TODO: change this\n",
        "        self.lr = lr  ###### TODO: change this\n",
        "        self.epochs = epochs ###### TODO: change this\n",
        "        self.threshold = 0.5 ###### TODO: change this\n",
        "\n",
        "    def sigmoid(self, z: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Sigmoid function.\n",
        "        Parameters:\n",
        "            z: the input\n",
        "        Returns:\n",
        "            the sigmoid of the input\n",
        "        \"\"\"\n",
        "        ##### YOUR CODE STARTS HERE #####\n",
        "        ret= 1/(1 + np.exp(-z))\n",
        "        \n",
        "        ##### YOUR CODE ENDS HERE #####\n",
        "        return ret\n",
        "\n",
        "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
        "        \"\"\"Train the classifier.\n",
        "        Use the logistic regression update rule as introduced in lecture.\n",
        "        Parameters:\n",
        "            X_train: a numpy array of shape (N, D) containing training data;\n",
        "                N examples with D dimensions\n",
        "            y_train: a numpy array of shape (N,) containing training labels\n",
        "        \"\"\"\n",
        "        N, D = X_train.shape\n",
        "        self.w = np.random.randn(D+1) #+1 for bias term \n",
        "        X_train_stacked = np.hstack((np.ones((N,1)),X_train)) #add one more dimension with full of ones\n",
        "        \n",
        "\n",
        "        ##### YOUR CODE STARTS HERE #####\n",
        "        n_class=len(np.unique(y_train))\n",
        "        all_w=np.zeros((n_class,D+1))\n",
        "        for p in range(n_class):\n",
        "          binary_y=np.array(p==y_train,dtype=int)\n",
        "          for  epochs in range(self.epochs):\n",
        "              h=np.dot(self.w,X_train_stacked.T)\n",
        "              h=((h-min(h))/(max(h)-min(h)))#normalization to aviod infinity in sigmoid for extreme values\n",
        "              h=self.sigmoid(h)\n",
        "              grad=np.dot((h-binary_y),X_train_stacked)/N\n",
        "              self.w-=self.lr*grad\n",
        "          all_w[p]=self.w.T\n",
        "        self.w=all_w\n",
        "        return(self.w)\n",
        "\n",
        "     \n",
        "        ##### YOUR CODE ENDS HERE #####\n",
        "        pass\n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Use the trained weights to predict labels for test data points.\n",
        "        Parameters:\n",
        "            X_test: a numpy array of shape (N, D) containing testing data;\n",
        "                N examples with D dimensions\n",
        "        Returns:\n",
        "            predicted labels for the data in X_test; a 1-dimensional array of\n",
        "                length N, where each element is an integer giving the predicted\n",
        "                class.\n",
        "        \"\"\"\n",
        "        N, D = X_test.shape\n",
        "        y_test = np.zeros(N)\n",
        "        ##### YOUR CODE STARTS HERE #####\n",
        "        X_test_stacked = np.hstack((np.ones((N,1)),X_test)) #add one more dimension with full of ones\n",
        "        y_hat= self.sigmoid(np.dot(self.w,X_test_stacked.T))\n",
        "        y_test = np.argmax(y_hat, axis=0)    \n",
        "        \n",
        "        ##### YOUR CODE ENDS HERE #####\n",
        "        return y_test"
      ],
      "metadata": {
        "id": "HhhTL6cRZix4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.03\n",
        "n_epochs = 100\n",
        "\n",
        "lr = Logistic(learning_rate, n_epochs)\n",
        "lr.train(X_train_CIFAR, y_train_CIFAR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPbSpN6vnZxd",
        "outputId": "c63fe34d-ff13-4f44-932a-7c74b7616bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -0.7003843 ,  -0.81175956,  -1.87924774, ...,   3.98318311,\n",
              "          3.53406665,   1.50980446],\n",
              "       [ -2.2391535 ,  -1.56344586,  -2.56174846, ...,   4.89070317,\n",
              "          4.6118736 ,   2.69309659],\n",
              "       [ -3.77273144,  -2.4658642 ,  -3.25664895, ...,   2.5662606 ,\n",
              "          2.13562823,   0.09125428],\n",
              "       ...,\n",
              "       [-11.5309244 ,   0.40119672,  -0.34207332, ...,  -4.14802567,\n",
              "         -4.7725829 ,  -6.76049326],\n",
              "       [-13.1000256 ,   2.25779573,   1.45282496, ...,  -4.52532805,\n",
              "         -4.84065745,  -6.6193168 ],\n",
              "       [-14.68011719,   8.50334997,   7.59677739, ...,  -1.58052132,\n",
              "         -1.66952707,  -3.35207266]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = lr.predict(X_train_CIFAR)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_CIFAR)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi9Y-mVJwF5b",
        "outputId": "f8ab5d46-6f30-4451-f20c-b9fb16396f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 17.522500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = lr.predict(X_val_CIFAR)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_CIFAR)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzSmp38bwF9M",
        "outputId": "9ab21034-ea35-4599-df78-9fa71f2b968c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 17.570000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = lr.predict(X_test_CIFAR)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_CIFAR)))\n",
        "\n",
        "lr\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek9gs1awmWRm",
        "outputId": "1c0d6e22-b56e-41d2-c289-5a961a0d4387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 17.540000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in exp\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Logistic at 0x7f2fd9787990>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_submission_csv('Logistic_submission_CIFAR.csv', lr.predict(X_test_CIFAR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7GoTEPnmb6_",
        "outputId": "04c7df70-d8ac-4f1c-a2b8-3b2aee13faee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_epochs=[10,30,50]\n",
        "Accuracy_train_accumulated = []\n",
        "Accuracy_test_accumulated = []\n",
        "for i in range(len(arr_epochs)):\n",
        "  lr = Logistic(0.1, arr_epochs[i])\n",
        "  lr.train(X_train_CIFAR, y_train_CIFAR)\n",
        "  pred_lr = lr.predict(X_test_CIFAR)\n",
        "  Accuracy_train_accumulated.append(lr.predict(X_train_CIFAR))\n",
        "  Accuracy_test_accumulated.append(lr.predict(X_test_CIFAR))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOTRqvjY9Tu8",
        "outputId": "6e91ed45-0d40-49cc-dcc8-fc6e0d3d415a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots(1,2,figsize=(16, 8))\n",
        "ax[0].plot(Accuracy_train_accumulated, 'h');\n",
        "ax[1].plot(Accuracy_test_accumulated, 'h')\n",
        "ax[0].set(title='Training Set Accuracy', xlabel='Number of Epochs')\n",
        "ax[1].set(title='Test Set Accuracy',xlabel='Number of Epochs')\n",
        "ax[0].grid()\n",
        "ax[1].grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "GDHpBiHjIhaG",
        "outputId": "acf1d512-4fd1-4c15-e6f0-e538eae4c910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5gAAAHwCAYAAADD8MCjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5hkZZk34N/b0xOYwBAdQBCUICrBwMqqqztGxLAofLqYCLoiigJKDpIEEUSS4goGwIi4mFZBcV3b8OmioggSBBEFJMMAk2d6+nx/VDU0883AwLxVNd1739dV13SdOn3e51Q/PW//6pyqU5qmCQAAAKysvl4XAAAAwNggYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYDJmFBKuaSUsnvtdQEAgBUnYNIzpZQ5I25DpZT5I+6/7fFsq2maHZumOb/2uo9XKeXwUspN7X24tZTy9RX8vj1KKb9YwXXPK6UMllLWX7lqAeCJqzmPt7c3UEr5t8dY512llOtKKbNLKXeWUi4upUxbgW3PLKXcuoJ1HFNKaUop269o7cDDBEx6pmmaqcO3JDcnef2IZV8ZXq+U0t+7Kldc+6joO5K8or1P2yX5ceUxpiTZJckDSd5ec9srMPao+DkA0B0rOo/XUkr55yQfTfKWpmmmJXlGkhV6IfdxjFGS7Jbkvva/XWOeZawQMFnlDL/KWEo5pJRyR5JzSylrllK+V0q5u5Qyq/31hiO+56FXPYePBpZSTmmve1MpZccnuO5TSyk/a79S+l+llLNKKV9eTun/kOSHTdPcmCRN09zRNM05I7Y1vZTy+VLK7aWUv5dSji+ljCulPCPJZ5K8oP2q7/2P8vTskuT+JMclecRpvqWUtUop55ZSbmvvy7dHPLZTKeWKUsqDpZQbSymvbi//aynlFSPWO2Z4/0opm7RfwX1XKeXmJP/dXv6NUsodpZQH2s/Ns0Z8/2qllE+UUv7WfvwX7WXfL6V8YKl6ryylvPFR9hWAUaiU0ldKObQ939xbSrmwlLJW+7FJpZQvt5ffX0r5TSllRinlhCQvTvKp9lz4qWVs+h+S/Kppmt8nSdM09zVNc37TNLPb257Yns9vbh/d/Ex7DpqS5JIkG4w4wrrBcsp/cZL1k+ybZNdSyoQR+7XMOa792D+VUn7Z3qdbSil7tJc/4qhsWeqMpfY8u08p5YYkN7SXndHexoOllMtLKS8esf640jpb6sb23yaXl1I2av998omlfg7fLaV8cEV+ZlCTgMmqar0kayXZOMleafXque37T0kyP8myJp9h2yf5U5J1kpyc5POllPIE1v1qkl8nWTvJMWkdoVye/0myWynloFLKdqWUcUs9fl6SwSSbJXlOklcl+bemaa5Nsndak+bUpmnWeJQxdk/ytSQXJNmylPK8EY99KcnkJM9K8qQkpyVJKeX5Sb6Y5KAkayR5SZK/PsoYS/vntF4l3qF9/5Ikm7fH+F2Ska9Sn5LkeUlemNbP7+AkQ0nOz4gjrqWUbZM8Ocn3H0cdAIwOH0jyhrTmjw2SzEpyVvux3ZNMT7JRWnPr3knmN01zRJKfJ3l/ey58/zK2e1mSHUopx5ZSXlRKmbjU4x9LskWSZ6c11z45yVFN08xNsmOS20YcYb1tObXvnuQ/k1zYvv/6EY8tc44rpWyc1tz4ySTrtse/4tGeoKW8Ia2/RZ7Zvv+b9jbWSuvvkG+UUia1H/tQkrckeU2S1ZO8M8m8tObZt5RS+pKklLJOkle0vx+6q2kaN7ee39IKPK9ofz0zyaIkkx5l/WcnmTXi/kBaYS1J9kjy5xGPTU7SJFnv8aybVpAdTDJ5xONfTvLlR6nrbUn+K8ncJPcmOaS9fEaShUlWG7HuW5L8ZEQdv3iM5+gpaYW1Z7fv/zDJGe2v128/tuYyvu/sJKc91vPevn/M8P4l2aT9XDztUWpao73O9LReBJifZNtlrDcprT8wNm/fPyXJp3vdd25ubm5udW5LzePXJnn5iMfWT7I4SX9ageiXSbZZxjYemp8fZZwd0wqA9yeZk+TUJOOSlPbcu+mIdV+Q5Kb21zOT3PoY256c5MEkb2jfPzvJd9pfP9ocd1iSby1nm4/Yp6Xn+/Yc+rLHqGvW8LhpvSC+03LWuzbJK9tfvz/Jxb3uC7f/nTdHMFlV3d00zYLhO6WUyaWUs9unpTyY5GdJ1ljGUcJhdwx/0TTNvPaXUx/nuhskuW/EsiS55dGKbprmK03TvCKt4LV3ko+UUnZI68jr+CS3t0+fuT+tietJj7a9pbwjybVN0wy/KvqVJG8tpYxP65Xg+5qmmbWM79soyY2PY5ylPbTP7VNzPtY+NefBPHwkdJ32bdKyxmr/LL+e5O3tV1ffktYRVwDGno2TfGvEfHdtkiVpvdj6pbReIL2g/ZaOk9vz2AppmuaSpmlen9bRvZ3SCmz/ltaRw8lJLh8x7g/ay1fUG9N6Yfni9v2vJNmxlLJuHmWOS8V5NklKKQeWUq5tn4Z7f1ov4q6zAmONPFvo7THP0iMCJquqZqn7ByR5epLtm6ZZPa3TPJPWK5adcnuStUopk0cs22hFvrFpmsVN03wjyZVJtkpr8liYZJ2madZo31Zvmmb4/YtL7++y7Jbkae33P96R1qu266R1mswt7VqXdXrtLUk2Xc4256Y1IQ9bb1m7M+Lrt6Y1ob8irQlvk/bykuSeJAseZazz0zrC+/Ik85qm+dVy1gNgdLslyY4j5rs1mqaZ1DTN39vz47FN0zwzrVNNX5eHP0xnRebC1opNM9Q0zY/T+nyArdKag+YnedaIMac3rQ8gWtFt757WC8w3t+fZb6T14vBb8+hzXLV5tv1+y4OTvDmts5LWSOuD/Yb/3nm0sb6cZKf221CekeTby1kPOkrAZLSYltbEcX/7gwKO7vSATdP8LclvkxxTSplQSnlBHvlejEdov3H/taWUae0PONgxrfdDXtY0ze1JLk3yiVLK6u3HNy2tT8RLkjuTbDjywwSW2vYL0ppQnp/W6cHPTmtC/WqS3drbvyTJp0vrA5HGl1KGQ/jnk+xZSnl5e9wnl1K2bD92RVofYjC+lLJdkv/zGE/LtLSC8r1pTZgfHfF8DSX5QpJTSykbtI92vmD4PTLtQDmU5BPxqirAWPaZJCe035uYUsq6pZSd2l+/tJSydfsMpAfTOnV2qP19dyZ52vI2WlofWLdre54r7c8Y+Ock/9Oegz6b5LRSypPa6z+5fRbR8LbXLqVMX862n5zWC6Cvy8Pz7LZJTkprnn20Oe4rSV5RSnlzKaW/lLJ2KeXZ7U1fkWTn9plYmyV512M8d9PSOop6d5L+UspRab3Xctjn0jo7avP2c7BNKWXtJGma5ta03r/5pSQXNU0z/zHGgo4QMBktTk+yWlqvIP5PWqe9dMPb0noPx71Jjk/rNM+Fy1n3wSSHp/VR7fen9YFB722aZvjT4nZLMiHJNWm9n+I/0npfStJ6BfbqJHeUUu5ZxrZ3T+t9IFc1rU+nvaNpmjuSnJHkde3Q/Y60JurrktyVZP8kaZrm10n2TOtDfx5I8tO0Tl9Kkg+nFVxnJTk2j/1hAF9M8rckf2/vx/8s9fiBSa5Ka4K7L62JuW+p7986rVdZARibzkjy3SSXllJmpzVXDF9Tcr205r8H0zp19qd5+EXHM5L8n9L6JPQzl7HdWUnendanrT6Y1lzy8ebhS6IckuTPSf6n/TaO/0rr7Kc0TXNdWh+S95f2KbRLf4rsO5Jc0TTNpUvNs2cm2aaUslWWM8c1TXNzWmcTHdBefkVa4TRpzb2L0gq45+eRH4y3LD9M62+c69OabxfkkafQnprWBxBd2n4OPp/W30fDzk9rnvVCLj1TmmaFz0aA//VKKV9Pcl3TNB0/gjoWlVJ2S7JX0zT/1OtaAGCsaZ+99OUkGzf+yKdHHMGER1FK+Yf2qax9pXXtyJ3iPQ1PSPu9rO9Lcs5jrQsAPD7tD0vaL8nnhEt6ScCER7deWh8xPiet02Te27Qv8MyKa78H5u60ThFyTS4AqKiU8oy03p6zflpvK4KecYosAAAAVTiCCQAAQBUCJgAAAFX0d2Kj66yzTrPJJpus9Hbmzp2bKVOmrHxBXabu7lJ3943W2tXdXbXqvvzyy+9pmmbdCiX9r2ZuVnc3qbv7Rmvt6u6urszNTdNUvz3vec9ravjJT35SZTvdpu7uUnf3jdba1d1dtepO8tumA3PV/7abufknvS7hCVF3d43Wuptm9Nau7u7qxtzsFFkAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgilUyYP7wpxfkuD3ekt/++yk5bo+35L//7zd7XRJU84fffDdXHPD0/OOPd84VH9oyV//u0l6XBFX94Wdfy7X7bZZ//PHOuXa/zXLlLy/qdUlUcN+frs7lB2yff/zxLvntAdtn1o3X9LokqObe6/6Uz7z9Lbn830/JZ97+ltx3w597XRJU1c0eX+UC5hEHvytXffrLmTx/dkqSyfNn53dnfiFHHPyuXpcGK+2iI16VLb6zZ5415a5MGrckz5p6Z572zbfkoiNe1evSoIqL9/+nbHHp+7PZ9HszadySbDb93mx+8V65eP9/6nVprITLTnxfVvvSS7LNlOszadxgtp1yfSad++JcduL7el0arLQfHvnhnHf0AZm7eHaSZO7i2Tn3yP3zwyM/3OPKoI5u9/gqFzCn3PZASpLSvj/89ZTbHuhdUVDJsxfekNX6BzO+byhJMr5vKKv1D+bZC2/ocWVQx7PG3bLMHn/WuFt6XBkrY/X7frrMn+vq9/20x5XByrvuxmsf13IYbbrd46tcwAQAAGB0EjABAACoYpULmHM3mJ4mSdO+P/z13A2m964oqOSKiZtn/mB/Fg+1fvUWD/Vl/mB/rpi4eY8rgzquXrLRMnv86iUb9bgyVsaDa/3zMn+uD671zz2uDFbelps+43Eth9Gm2z2+ygXME07+fJ677zszb7VprWA5efU8d9935oSTP9/r0mCl7XLCpfnLzl/L1XNmZMGScbl6zoz8ZeevZZcTfJIsY8NrTv9FbnjNOfnzA2tnwZJxueH+tXPDa87Ja07/Ra9LYyVsf9ins2DPn+cPc7fIgiX9uWLu07Ngz59n+8M+3evSYKXtcPxHsufxp2fK+GlJkqkTVs+ex5+eHY7/SI8rgzq63eP9HdnqSnrZi3bOy160cwYGBjJz5sxelwNVPeu5r0qee53+Zsza5oW7JC/cRY+PMWtu+sxs94nL/FwZk9bafLPs/eWv6W/GrG72+Cp3BBMAAIDRScAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqVihgllI+WEq5upTyx1LK10opkzpdGACwfOZmAFZF/Y+1QinlyUn2TfLMpmnml1IuTLJrkvM6VdSZB78zm0zdKFsseGG++7Oj8ucHb82HTvlCp4aDrjrzqN3zpP6t8+wFW+eCn308dy2+Mvt+5Eu9LguqOfOod+RJ/ds+1ON3Lr4y++nxqnoxN599xjm5btblWa2sne8MfC1br/ePeefee3ZqOOiqT59+Rh5ofpPBORvlV7//XNaa8I95zz7v73VZUM05n/l07p3/y4d6fL1pL82e//aujoy1oqfI9idZrZTSn2Rykts6Uk2Si47/t7yy/0155vwXZ+rQ5Dxz/kuy44Q35aLj/61TQ0LXfPGj++UVg2/JdvOfk6lDk7Pd/OfmFUveli9+dL9elwZVtHr8bY/o8Vfq8U7p2tx82BEfzN/uvylTyrqZ0EzIlLJu/nzn9TnsiA92akjomo9+7F25d87tWTx7kyxZMjGLZ2+Su2bdmo9+rDN/fEO3ffRj78qd99z8iB6/9Y4bOtbjjxkwm6b5e5JTktyc5PYkDzRNc2lHqkkyZckzM21oaiY1E5Mkk5qJmTY0NVOWPLNTQ0LXTF/8jKw+NCWTmglJkknNhKw+NCXTFz+jx5VBHXq8O7o9N8+fuCATmonpb1onPvU3/ZnQTMz8iQs6NSR0Td+EJksGJ2VoqNXfQ0P9WTI4KX0Tmh5XBnV0u8dX5BTZNZPslOSpSe5P8o1SytubpvnyUuvtlWSvJJkxY0YGBgaqF9uJbXbCnDlzRk2tI6m7t0bTPozW51zdvTUW9mFVYW5+/Ebr75G6e2s07cNofc7V3Vud2IfHDJhJXpHkpqZp7k6SUso3k7wwySMmsaZpzklyTpJst912zcyZM59QQT/46e+W+9gT3Wa3DQwMjJpaR1J3533np9ct97HRsg/J6HrOR1J3542VHh8Fujo3f/tnX1/uY6Pl5zqafo9GUnfn/c/vvrjcx0bLPiSj6zkfSd2d1+0eX5H3YN6c5B9LKZNLKSXJy5NcW72StrnjrsnsvjlZUBYmSRaUhZndNydzx13TqSGhax4Yf20e7JubBWVRkmRBWZQH++bmgfEd+5WCrtLjXdPVuXm1hZOyqCzMYBlMkgyWwSwqC7PaQh9cy+g3tKhkXP+C9PW1+ruvbzDj+hdkaFHpcWVQR7d7fEXeg3lZkv9I8rskV7W/55yOVJNklyM/l0sWfSPXrPazzOmbm2sm/yyXLPpGdjnyc50aErpmt8PPyH+N+0p+u9rvMqdvXn672u/yX+O+kt0OP6PXpUEVux1+Rn60VI//SI9X1+25+cQTTstmM7bI3ObuLCqLMre5O5vN2CInnnBap4aErjn80M/nSWtumPHT/ppx4xZm/LS/5klrbpjDD/18r0uDKg4/9PPZcL3NH9HjG663ecd6fEVOkU3TNEcnObojFSzD8CVJBgYG8i8zj+vWsNAVw5ckGRgYyK4zD+pxNVDffnq8K7o9N7cuSbLnqDotDFZU65Ik79ffjFmtS5K8qys9vqKXKQEAAIBHJWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABV9Pe6gGU5+sNvzc83m567yu/ypPOflxdePyvHn/C1XpcFVZxw5C755WZr5299f8jG522bF153V4742Ld7XRZUc8yRu+Tnm6+dO8sfMuP8bfOi6+7KcSfq8dHuiCM+lEs33SG3brhuNvzCD7PDjT/I8Sec1uuyoIrDjvxA/utpr3uov1/1l+/lhOM/2euyoJojPvzeXPWcZ+ePa2yVrb55drb9/ZX5yEfO6shYq9wRzHd/6sBctPlNuav8OqWZl7vKZfn20/+ad3/qwF6XBivtg2e8J1/b4rb8re/ylGZe/tZ3eb72zDvzwTPe0+vSoIp3n/Xu/McWt+XO0urxO8vl+eYz7sy7z3p3r0tjJex6yln5wkvells2WjfN+L7cstG6+fxL3p5dT+nMHyfQTbt+4lM578V7PKK/v/DiPbLrJz7V69Kgind/5rhc8NK35oo1np15ZUquWOPZ+epLd827P3NcR8Zb5Y5gXjX97pShOQ/dL82iJIty1fS7e1cUVPLbNeelNP9/f/92zXm9Kwoq+uPqC5f5f/gfV1/Yu6JYaVetv1WaCeMeXtDfl6a9HEa7q9bbetn9vd7WPasJarppo00yt0x76P6iMjGLMjE3bbRJR8Zb5Y5gAgAAMDoJmAAAAFSxygXMrR9YN02ZmqZMSJI0ZUKaMjVbP7BujyuDlbfdrMnL7O/tZk3ucWVQx1YPTlxmj2/14MQeV8bK2Pr2P6YsWpIMDrUWDA6lLFqSrW//Y28Lgwq2vuOqZff3HVf1tjCo5Km3/DVTmtmZ0LTerjKhWZgpzew89Za/dmS8VS5gfvb9p+QNf9okT2q2T1MmZ0azfd7wp03y2fef0uvSYKWdtt/Zecs1M7Lx0PPSlMnZZMnz8pZrZuS0/c7udWlQxWf3+Wx2vnZGZjStHl+veV52vnZGPrvPZ3tdGivhggP3ybt+9uVsdMvdKYuH8pSb78q7fvblXHDgPr0uDVbaBQe8P+/8+XkP9/ctd+WdPz8vFxzw/l6XBlV8du+j8tafXJBn339FJjdz85z7f5+3/uSCfHbvozoy3ir3IT9JHrokycDAQGbOnNnbYqCy4UuS6G/GquFLkujxseX4E07L8Wn/XN/16iSv7nVJUM0Jx38yJ6Td3+/U34w9w5ckGRgYyMyd90527txYq9wRTAAAAEYnARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKroX5GVSilrJPlckq2SNEne2TTNrzpV1FGHvy+LljwzkybOyg8u+WMm9F2V4048u1PDQVcdddB709dslUy+LwPfuzpNuTLHflx/M3Ycc8h7kiXbPNTjZdwfcvRJ5/S6rDGn23Pzhw88MFc+98rcNnh7NvjqBtn299vkuI9/vFPDQVcdeciHcu22v8/Ng/dk46+uk2f+4bk57qRP9LosqObIgz6Ua5/zcI8/6w/PzbEd6vEVPYJ5RpIfNE2zZZJtk1zbkWqSHH3wx9PXv0EmTbwv6VuSSRPvS9/4jXL0wSYxRr+TP3By+lZ7cjL53qRvSTL53pTVNsrJHzi516VBFR//wEnJxI0e0ePNxKe0llNb1+bmPc7cPT/c9oe5ZfC2LGiSWwb/nh9s84PscebunRoSumafM96cS7f6UW4avDsLmuQvg3fnB1tdmn3OeHOvS4Mq9jnjzbl0m0f2+CUd7PHHPIJZSpme5CVJ9kiSpmkWJVnUkWqSDPZNzPi+uQ8v6BtKMpTBvtU7NSR0zbzJk5K+eQ8vaPf3vMn6m7Fh7uTVkr75Dy9o9/hcPV5Vt+fme550Y+YvTJKSJFnclCxuWsthtLt5xi3L7O+bZ9zS07qglm73+IqcIvvUJHcnObeUsm2Sy5Ps1zTN3JErlVL2SrJXksyYMSMDAwOVS01HttkJc+bMGTW1jqTu3hpN+zBan3N199ZY2IdViLn5cRqtv0fq7q3RtA+j9TlXd291Yh9WJGD2J3lukg80TXNZKeWMJIcm+fDIlZqmOSfJOUmy3XbbNTNnznxCBf3oB1cu97Enus1uGxgYGDW1jqTuzhu4ZPT3dzK6nvOR1N15Y6XHR4Guzs2nXLD8x0bLz3U0/R6NpO7O+8QY6O9kdD3nI6m787rd4yvyHsxbk9zaNM1l7fv/kdak1hH9QwuTof5kqF3aUF8y1N9aDqPc5HkLltnfk+ct6G1hUMmUefOX2eNT5s1/9G/k8erq3LzOXZtmtb5kfGmStP5dra+1HEa7p9y50TL7+yl3btTjyqCObvf4YwbMpmnuSHJLKeXp7UUvT3JNR6pJcuzJB2Vo8S1ZsHCtZGhc5i9YK0OLb8mxJx/UqSGhaw7+5MFp5t+SzFs7GRqXMnftNPNvycGfPLjXpUEVB33ykJSFNz+ix8vCm3PQJw/pdWljSrfn5vP2PT+vvvLV2aj/yZlUkqf0PzmvvvLVOW/f8zs1JHTNWftdmFf/8VV5Wv+6mVSSp/U/Ka/+46ty1n4X9ro0qOKs/S7Mjkv1+I4d7PEVukxJkg8k+UopZUKSvyTZsyPVtA1fkmQ0HXqGFTV8SRL9zVg1fEkSPd5x3Z2b25ckeejn+tZOjgbdNXxJEv3NWHVsF3t8hQJm0zRXJNmuc2UAAI+HuRmAVdGKXgcTAAAAHpWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVfT3uoBlOfbgD+Xbm78+t288PRt89id5ww3fylEnn9nrsqCKow/dL9/Z9F9yx8ZrZr3P/jg7/fk7OfYk/c3YcfghH8rFm732oR7f8Ybv5sSTz+h1Wayko4/8UF7UvCjPWLJuLv3RRflV3y9y9EdO63VZUMURR78va/VvkdfMf0ZO+cVpmb3kphx7tLmZseOow/fKP/xpdja7/k/57hZPz++3XD1Hn3B2R8Za5Y5g7nryV/KZl78tt28yPRnfl9s2mZ5/f/nu2fXkr/S6NFhpu3z8Cznnpbvljk3WTMb35Y5N1sw5L9s9u3z8C70uDarY5eNfyLkve9sjevy8l++mx0e5M48+K+8afEOesWTdlJQ8Y8m62XPxG3Pm0Wf1ujRYaQccf3jeuvhfstO8rTNtaHLeMHebvHnha3LA8Yf3ujSo4uMf2Odcg2kAACAASURBVCu7fu/ybHbd1cni+dn8uqvzpv/8bT7+gb06Mt4qdwTz9+tvnGbCuIcX9PelaS+H0e6P622xzP7+43pb9KwmqEmPj00vWLxx+lIeul9SUtrLYbTbemjjTB+a8tD9Sc2ETGomZOsh/c3YsP0Nd6csmvfwgiWLU5YszvY33N2R8Va5I5gAAACMTgImAAAAVaxyAfM5t/8tZdGSZHCotWBwKGXRkjzn9r/1tjCoYKs7rl9mf291x/W9LQwq0eNj06/G/y1DadKkSZI0aTKUJr8ab25m9Luq7295oG9uFpRFSZIFZVEe6Jubq/r0N2PDZZuvm2bC5GTc+NaCcePTTJicyzZftyPjrXIB84KD35b3/vj8bPDXB5LFQ9ngpvvz3h+fnwsOfluvS4OVdtFB78xe/31+1vvrrGTxUNa/6b7s9d/n56KD3tnr0qCKiw56Z/b48Rcf0eN7/PiLenyU2/fYfXLu+G/l2nF3p0mTa/rvzrnjv5V9j92n16XBSvvEkR/NhRMvzrenXJnZffPyrSlX5sKJF+cTR36016VBFQd98px84/Xb5YYtn5WMXy3XP2OrfOP12+WgT57TkfFWuQ/5SZKjTj4zRyUZGBjIzL1eluRlvS4Jqjn2pDNzbIb7+xVJXtHrkqCqE08+IydGj481w5ckGRgYyA4zd8kO2aXHFUE9w5ckGRgYyEEzP9jjaqC+4UuSDAwMZKeZM7NTB8da5Y5gAgAAMDoJmAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBX9K7piKWVckt8m+XvTNK/rXEnJsYfvkUkz3pDX3712PnbltzPv79/KcSed38khoWs+fORuWXf1f8wr7980Z/z607lr1mU54UT9zdhxzBHvzFrT/yGvvP9pOePX/557Z/0mx534hV6XNSZ1c24+8sAP5p6nvTI/3my9vOKs72ftm36Q40/5ZCeHhK454sDDM3uLV+WSTVbPa84ZyLTrL8nxp5zU67KgmgMPPSYPPHPHDKw3PTO/eFnWuvo/c9JJx3dkrMdzBHO/JNd2pIoR9j/t9Owy7l3Z+c61s/pgsssda+fNE/4t+592eqeHho474qSjs2vz1rxm1tMzbWhyXjvr6Xlr31tyxElH97o0qOKok07Im/LmvGbWFu0e3yL/2vfmHHXSCb0ubazqytx83LFfyjde+Y5csvl6mT2+LxdvsX6+8co9c9yxX+r00NBxJ3zsm/mPV/6ffOep0zN7fF++/dTp+cYr/zUnfOybvS4Nqjjokz/Jf770X3Lp+hMye3zJpetPyLdftnMO+uRPOjLeCgXMUsqGSV6b5HMdqWKErYe2zBqLk9WGWvdXG0rWWNxaDqPdlkuekulLpmRSMyFJMqmZkOlLpmTLJU/pcWVQx+ZL1ltmj2++ZL0eVzb2dHNuvnbjDfLAhL4s7G/92bCwvy8PTOjLtRtv0OmhoeOue/J67f4uSZKF/SUPTOjLdU/2/xZjwy3rTF1mj9+yztSOjLeip8ienuTgJNOWt0IpZa8keyXJjBkzMjAwsNLFLa0T2+yEOXPmjJpaR1J3b42mfRitz7m6e2ss7MMqxtz8OIzW3yN1d8OE5T4yevZhtD3nD1N3N0xZ7iOd2IfHDJillNcluatpmstLKTOXt17TNOckOSdJtttuu2bmzOWu+qhuvPwHy33siW6z2wYGBkZNrSOpu/O+9Msbl/vYaNmHZHQ95yOpu/PGSo+v6ro9N5993o+X+9ho+bmOpt+jkdTdeZ//0i+X+9ho2YdkdD3nI6m78z7ztd8s97FO7MOKnCL7oiT/Ukr5a5ILkryslPLl6pW0XdV3Xe4fn8xvVza/L7l/fGs5jHbXjbs5D4ybmwVlUZJkQVmUB8bNzXXjbu5xZVDHDePuWGaP3zDujh5XNuZ0dW5+xt9uy/RFQ5k42Hr/ysTBoUxfNJRn/O22Tg0JXbPl3+9o93eTJJk42GT6oqFs+Xf/bzE2bHTPnGX2+Eb3zOnIeI8ZMJumOaxpmg2bptkkya5J/rtpmrd3pJokp39w/1y46HO5aL1782B/ctF69+TCRZ/L6R/cv1NDQteccMix+erQ1/L9Nf+U2X3z8v01/5SvDn0tJxxybK9LgyqOO+SIfH3ownx/zevbPX59vj50YY475IhelzamdHtuPurod+RNPzo3r7n+9kxbNJTXXn973vSjc3PU0e/o1JDQNUccunPe9KOv5w03PZBpi4fyxr/cnzf96Os54tCde10aVPHxD7w0b/jvb+ZVty/KtMVNdrh9Ud7w39/Mxz/w0o6Mt8KXKemm4UuSDAwM5NCZb0zyxt4WBBUNX5JkYGAg+818X5L39bYgqGz4kiStHn9vkvf2tiCqGL4kycDAQGbu89q0Pl8IxobhS5K8cWAgM9/z0iSd+cMbemX4kiQDAwOZudvMJNt3bKzHFTCbphlIMtCRSgCAx83cDMCq5PFcBxMAAACWS8AEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAq+ntdwLJ8dL9/zZ2bbZ3J9yffvuoXWfemP+aIUy/odVlQxQn775a7Ntsik2cl3/rjL7LOX6/Jh0/5aq/LgmqO23+33Duix9f+6zU5So+PegccsHdevdn89D/td/nRvz8v379hUk4/9TO9LguqOOSDH8grtnjwof7+0Q3TcvKpn+x1WVDNgR96f3bYfPZDPX7JDZNz6qmf7shYq9wRzKNO3j8PrrtNps4aysQlg5kyayiz19o6R528f69Lg5V22KkHZvY6T8/U+1r9PfW+ocxd41k57NQDe10aVHHYqQdm3lI9Pk+Pj3pnf2zfvO6Vv8y4TX+dofHzMm7Ty7LTq36Zsz+2b69Lg5V2zon75dU7/PQR/b3jq36ac07cr9elQRVnf2zfvPZVP3tEj7/+Vb/o2P/hq9wRzFmT1sva8xY8dH/80FDGDw3l3tXX62FVUMec/nWy9uAy+rt/nR5WBfXo8bHp6evfniUT5j50v+lflCaL8vT1b+9hVVDHFhvctsz+3mKD23pYFdTT7f/DV7kjmAAAAIxOAiYAAABVrHIBc80Fd2RB//gs7muVtrivLwv6x2fNBXf0uDJYeVMH71lmf08dvKfHlUEdenxs+tPt66dv0dSUwQlJkjI4IX2LpuZPt6/f48pg5V1/2wbL7O/rb9ugx5VBHd3+P3yVC5jHHXx6pt13Veau2ZeF/f2Zs2Zfpt13VY47+PRelwYr7cQPnZIp91+dOWu1+3utvky5/+qc+KFTel0aVHHih07J5KV6fLIeH/Xec+iZ+c6lL8iSG7dP3+LJGfzz9vnOpS/Iew49s9elwUrb67AzcsmlL3lEf19y6Uuy12Fn9Lo0qOI9h56Z/7z0RY/o8f+89EUd+z98lfuQnyQPXZJkYGAgM2fO7G0xUNnwJUn0N2PVUXp8TBq+JMnAwEBe9b6ZeVWP64Gahi9Jor8Zq4YvSdKNHl/ljmACAAAwOgmYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQxWMGzFLKRqWUn5RSrimlXF1K2a8bhQEAy2ZuBmBV1b8C6wwmOaBpmt+VUqYlubyU8qOmaa7pVFFHH/q+vHpo4zwlz82vLj4plwz+Lced+ulODQddddQh782rm6fmKXlOfnnxSfnB4F9y3Kln97osqObog9+THbLpiB6/Mcedek6vyxpruj43n/DB/5NJgxtm9hpTc/lF386Cvr/niDO+0anhoKuOOfBfMm3h0x7q7wf6/5LjTvtur8uCao4/YKestuipD/X4/L6/5MgzOtPjj3kEs2ma25um+V3769lJrk3y5I5Uk+SSI/bJbkM7Zf1slwl9k7J+tsvu/TvlkiP26dSQ0DXfOmzf7N68IRvkeZnQNykbZLvs3r9zvnXYvr0uDar41mH7ZrfsvFSP76LHK+v23PyZfd+dxVO2zOw1pyXj+jN7zWlZPO3p+cy+7+7UkNA1Z+2/RzJpm0f0d9+UbVrLYQz49P57ZnC1rR/R44PTtsmn99+zI+OtyBHMh5RSNknynCSXdaKYJFln4bMysX/yQ/f7+yakPxOyzsJndWpI6JoNF2+5zP7ecPGWPawK6tHj3deNufn+cdOT/hF/MvSNS/ray2GUm13WWWZ/zy7r9K4oqOjBsvYye/zBsnZHxlvhgFlKmZrkoiT7N03z4DIe3yvJXkkyY8aMDAwMPKGCpjzKY090m902Z86cUVPrSOruvLHQ38noes5HUnfnjZUeHy26NTc/mtHycx1Nv0cjqbu3RtM+jNbnXN291Yl9WKGAWUoZn9YE9pWmab65rHWapjknyTlJst122zUzZ858QgX95nvLf/vIE91mtw0MDIyaWkdSd+eNhf5ORtdzPpK6O2+s9Pho0M25+X++873lPjZafq6j6fdoJHV33ljo72R0Pecjqbvzut3jK/IpsiXJ55Nc2zTNqdUrWMo9E6/OwiXzMji0KEkyOLQoC5fMyz0Tr+700NBxt46/bpn9fev463pcGdShx7uj23PzGkseSAYHk6ElrQVDS5LBwdZyGOWmNfcss7+nNff0tjCoZPXm3mX2+OrNvR0Zb0Wug/miJO9I8rJSyhXt22s6Uk2SHU84K+cv+U5uz2+zaGh+bm9+k/OXfCc7nnBWp4aErnnjiWfm/CXfzG3t/r6t+W3OX/LNvPHEM3tdGlTR6vGLlurxi/R4fV2dm/c+87MZP/tPmTZrdrJkMKvPmp3xs/+Uvc/8bKeGhK7Z5/TzMjT3yof6e9qs2Rmae2X2Of28XpcGVbzv9HPTP/uRPd4/+8q87/RzOzLeY54i2zTNL5KUjoy+HMOXJGkdej40L+jm4NBhw5ckafX3IXlhj+uB2oYvSaLHO6cXc/PwJUlG02lhsKKGL0mivxmrhi9J0o0eX5EjmAAAAPCYBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKhCwAQAAKCK/l4XsCwHffit+adpf820Z96Z75w0Iz+fvXFOOf5rvS4Lqjjkw7vlRdP+nKnPvDPfPWlGfjFnk5z8ka/2uiyo5v/v8afl5I98uddlsZKOPeDtuWfrF+eHGzwrO5x3dta+6mc55hNf6XVZUMVx++2esuZrMvnedfOLn349g7O+l2NO/1Kvy4JqjvvgHmnWfF2m3r1Wfvqz/0gz67s55rQvdmSsVe4I5mnHvjk7Pv+yTN36zjSTk6nb3JnXbP/rnHbsm3tdGqy0M459c3Z4/v/NlHZ/T9nmzrz6+ZflDP3NGLHsHv+VHh/ljvvECblgh73yvQ23zYPjp+Y/N9w2X9/hPTnuEyf0ujRYaScdc2omN7tn2t3rZtLiZOpd62bq0J456ZhTe10aVPHR48/M5CW7Zfqda2XS4mT6nWtl6pI98tHjz+zIeKvcEcxnrnlDmikjFkxMmomt5TDabbmc/t5SfzNG6PGx6cYNnpxZ41d/6P6CcZOyYNyk3LjBk3tYFdSxcGjTrL3o4fvjl7Ru9w5t2ruioKLFizbJ9GX0+NxFm3RkvFXuCCYAAACjk4AJAABAFatcwLxm1uYpc5IsbC9YmJQ5reUw2l23nP6+Tn8zRujxsWnT2/6eNRc/mElLFiRJJi1ZkDUXP5hNb/t7jyuDlTex78bMn5AsHte6v3hcMn9CazmMBeMn/HWZPT5+wl87Mt4qFzA/ePSFufjXz8+cK2ekzEvmXLleLv718/PBoy/sdWmw0vY7+sL84DfbZ+6I/v7Bb7bPfvqbMaLV4y9YqsdfoMdHuaMOOCL/+sOz8/pb/5DVF8/Jv9x6Rf71h2fnqAOO6HVpsNIOOeZDmdN3buY86e4sGJ/MedJdmdN3bg455kO9Lg2qOPzIfTNn3Hl5YMZ9WTA+eWC9ezNn3Hk5/Mh9OzLeKvchP0keuiTJwMBAdjpkZnbqcT1Q0/AlSfQ3Y9XwJUn0+NgyfEmSgYGBzNxj7yR797YgqGj4kiQDAwOZOXPXJLv2tiCobPiSJK0ef1OSN3VsrFXuCCYAAACjk4AJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVCJgAAABUIWACAABQhYAJAABAFQImAAAAVQiYAAAAVCFgAgAAUIWACQAAQBUCJgAAAFUImAAAAFQhYAIAAFCFgAkAAEAVAiYAAABVrFDALKW8upTyp1LKn0sph3a6KADg0ZmbAVgV9T/WCqWUcUnOSvLKJLcm+U0p5btN01zTqaJOfP9783+3fG6u2myrbPOpc/Ki667IoZ/6dKeGg676//r7T1fk0E/qb8YOPd55vZibT933nVlj6I7MvXcof/mPk3PfuPVy4Blf6NRw0FX6m7Fu6R6/d9x6OahDPb4iRzCfn+TPTdP8pWmaRUkuSLJTR6pJsu/xh+Xs174jV2yxbRZOXC2/3+LZ+cxr3559jz+sU0NC1yyzv1+jvxk79HjXdHVu/vShe2bCPbdl9j1NFg31Z/Y9TSbdfVs+feienRoSukZ/M9Ytq8dX62CPr0jAfHKSW0bcv7W9rCOuXH+bLJg0OYPjJyRJBsdPyIJJk3Pl+tt0akjoGv3NWKfHu6arc/Nq992ahUv6M9iMS5IMNuOycEl/Vrvv1k4NCV2jvxnrut3jj3mK7IoqpeyVZK8kmTFjRgYGBmpt+iGd2GYnzJkzZ9TUOpK6e2s07cNofc7V3VtjYR9GG3Pzw0br75G6e2s07cNofc7V3Vud2IcVCZh/T7LRiPsbtpc9QtM05yQ5J0m22267ZubMmU+sohu/ttyHnvA2u2xgYGDU1DqSurtgDPR3Msqe8xHU3QVjpMdHga7OzTd99YTlPjZafq6j6vdoBHV33ljo72R0Pecjqbvzut3jK3KK7G+SbF5KeWopZUKSXZN8t3olbdvcfmUmLZiX/sWLkiT9ixdl0oJ52eb2Kzs1JHSN/mas0+Nd09W5ef5aG2biuMH0lyVJkv6yJBPHDWb+Wht2akjoGv3NWNftHn/MgNk0zWCS9yf5YZJrk1zYNM3VHakmyZlHnpi9v//lPOf6KzJx4fw85/orsvf3v5wzjzyxU0NC15x55InZ++Kl+vti/c3Yoce7o9tz8/s+dm4WrLtBpq1TMqFvMNPWKVmw7gZ538fO7dSQ0DX6m7HufR87N/OX6vH5HezxFXoPZtM0Fye5uCMVLMPwJUkGBgYy8/17dWtY6IrhyzXob8YqPd4d3Z6bhy/ZMJpOC4MVpb8Z6w7qYo+vyCmyAAAA8JgETAAAAKoQMAEAAKhCwAQAAKAKARMAAIAqBEwAAACqEDABAACoQsAEAACgCgETAACAKgRMAAAAqhAwAQAAqELABAAAoAoBEwAAgCoETAAAAKoQMAEAAKiiNE1Tf6Ol3J3kbxU2tU6Seypsp9vU3V3q7r7RWru6u6tW3Rs3TbNuhe38r2ZuVneXqbv7Rmvt6u6ujs/NHQmYtZRSfts0zXa9ruPxUnd3qbv7Rmvt6u6u0Vo3j260/lzV3V3q7r7RWru6u6sbdTtFFgAAgCoETAAA+H/t3XuMXGUdxvHvQ1vb9GIpVCMC0hYhSBNaCm20VihIBMqlBSWCFShWpCgIEomYGiTEBAgSCJEEsRIhNlysIoig3EoFSVtq0xuXQlsIQhpBwEJFKqU//zjvyOmwO3t2d3bO2d3nk0x65j23Z955d345Z86ZmllTVP0A86ayA3SRc7eWc7deb83u3K3VW3NbY731fXXu1nLu1uut2Z27tXo8d6XvwTQzMzMzM7Peo+rfYJqZmZmZmVkvUdoBpqRjJK2XtEHSJW3MHyzpjjR/maQxuXk/TO3rJR1dsdwXSXpa0hpJD0vaJzfvfUmr0uOeiuWeI+m1XL5v5uadKen59DizYrmvzWV+TtK/cvPK7O+bJb0qaV078yXp+vS61kialJtXZn93lHt2yrtW0hOSJuTmvZjaV0la0brUhXJPl7QlNx4uzc1rOMZ6UoHcF+cyr0tjerc0r8z+3lvS4vRZ95SkC9pYppJj3BpzbXZtblJu1+Ymcm12bS6Yuzq1OSJa/gAGABuBccBHgNXAgXXLfBu4MU2fCtyRpg9Myw8GxqbtDKhQ7iOAoWn63Fru9Hxrhft7DvCzNtbdDdiU/h2VpkdVJXfd8ucDN5fd32nfhwGTgHXtzJ8B3A8I+CywrOz+Lph7ai0PcGwtd3r+IjC6ov09Hbi3u2Os1bnrlj0BeKQi/b0HMClNjwCea+MzpZJj3I+G76trc/X6ew6uzc3M7tpcrf6ejmtzM3NXpjaX9Q3mFGBDRGyKiP8CtwMz65aZCdySphcBX5Sk1H57RGyLiBeADWl7lcgdEYsj4p30dCmwV4uyNVKkv9tzNPBgRLwREW8CDwLH9FDOep3NfRpwW0uSdSAi/gK80WCRmcCtkVkK7CppD8rt7w5zR8QTKRdUZ3wX6e/2dOdvo9s6mbtK43tzRKxM028DzwB71i1WyTFuDbk2t5Zrc4u5NreWa3NrVak2l3WAuSfw99zzl/lwB/x/mYjYDmwBdi+4bk/p7L7nkp0lqBkiaYWkpZJm9UTAdhTN/eX0dfkiSXt3ct2eUHjf6XKnscAjueay+ruI9l5bmf3dWfXjO4AHJP1N0rdKytTI5yStlnS/pPGprVf0t6ShZB/0v801V6K/lV0ieTCwrG5WXxjj/Y1rs2tzEa7N1f7ccm1uEdfm9g3s6orWmKSvA4cCh+ea94mIVySNAx6RtDYiNpaT8EP+ANwWEdsknUN2hvrIkjN1xqnAooh4P9dW5f7u1SQdQVbEpuWap6X+/jjwoKRn01nAKlhJNh62SpoB/B7Yr+RMnXEC8NeIyJ9RLb2/JQ0nK6wXRsRbrdy3WVe4Nreca3MLuTa3nGtzO8r6BvMVYO/c871SW5vLSBoIjAReL7huTym0b0lHAfOBEyNiW609Il5J/24CHiU7s9AKHeaOiNdzWRcAhxRdtwd1Zt+nUneJQon9XUR7r63M/i5E0kFkY2RmRLxea8/196vAXbTu8rgORcRbEbE1Td8HDJI0ml7Q30mj8V1Kf0saRFbAFkbE79pYpNeO8X7Mtdm1uQjX5gp+brk2l8K1uT1Rzk2oA8luHh3LBzfvjq9b5jvs/EMCd6bp8ez8QwKbaN0PCRTJfTDZjcn71bWPAgan6dHA87TohuWCuffITZ8ELI0Pbvp9IeUflaZ3q0rutNwBZDdVqwr9ncswhvZvbD+OnW+yXl52fxfM/Smye6um1rUPA0bkpp8AjqlQ7k/UxgfZh/1Lqe8LjbGycqf5I8nuBRlWlf5OfXcrcF2DZSo7xv1o9z1zbXZtbkrutJxrc+tyuza3MHea79rcKEsr36y6FziD7NeNNgLzU9vlZGcWAYYAv0l/MMuBcbl156f11gPHViz3Q8A/gFXpcU9qnwqsTX8ka4G5Fct9BfBUyrcYOCC37jfS+7ABOKtKudPzy4Ar69Yru79vAzYD75Fdxz4XmAfMS/MF3JBe11rg0Ir0d0e5FwBv5sb3itQ+LvX16jSO5lcs93m58b2UXBFua4xVJXdaZg7Zj6fk1yu7v6eR3WeyJjcWZvSGMe5Hh++ta3O1crs2Nze3a3O1crs2Nzd3ZWpz7ayBmZmZmZmZWbeUdQ+mmZmZmZmZ9TE+wDQzMzMzM7Om8AGmmZmZmZmZNYUPMM3MzMzMzKwpfIBpZmZmZmZmTeEDTOszJIWka3LPvy/psiZt+1eSvtKMbXWwn1MkPSNpcV37GEn/kbQq9zijifudLuneZm3PzMwMXJu7uV/XZuuVBpYdwKyJtgEnS7oiIv5ZdpgaSQMjYnvBxecCZ0fE423M2xgRTXF2ZwAAA59JREFUE5sYzczMrKe5Npv1M/4G0/qS7cBNwPfqZ9Sf5ZS0Nf07XdISSXdL2iTpSkmzJS2XtFbSvrnNHCVphaTnJB2f1h8g6WpJT0paI+mc3HYfk3QP8HQbeU5L218n6arUdinZf5L7S0lXF33RkrZKulbSU5IelvSx1D5R0tKU6y5Jo1L7pyU9JGm1pJW51zhc0iJJz0paKElp+SslPZ2289OiuczMzHBtdm22fscHmNbX3ADMljSyE+tMAOYBnwFOB/aPiCnAAuD83HJjgCnAccCNkoaQndXcEhGTgcnA2ZLGpuUnARdExP75nUn6JHAVcCQwEZgsaVZEXA6sAGZHxMVt5Ny37jKcL6T2YcCKiBgPLAF+nNpvBX4QEQcBa3PtC4EbImICMBXYnNoPBi4EDgTGAZ+XtDtwEjA+becnHXWmmZlZHddm12brR3yAaX1KRLxF9uH93U6s9mREbI6IbcBG4IHUvpascNXcGRE7IuJ5YBNwAPAl4AxJq4BlwO7Afmn55RHxQhv7mww8GhGvpctzFgKHFci5MSIm5h6PpfYdwB1p+tfAtFTEd42IJan9FuAwSSOAPSPiLoCIeDci3snlfTkidgCr0mvfArxLdub2ZKC2rJmZWSGuza7N1r/4ANP6ouvIzl4Oy7VtJ413SbsAH8nN25ab3pF7voOd71OOuv0EIOD8XGEZGxG1Ivjvbr2KrqvPWVS+H94HavenTAEWAccDf+pmNjMz659cm7vGtdl6HR9gWp8TEW8Ad5IVspoXgUPS9InAoC5s+hRJu6T7IsYB64E/A+dKGgQgaX9JwxptBFgOHC5ptKQBwGlkl8901S5A7R6WrwGPR8QW4M3cpTqnA0si4m3gZUmzUt7Bkoa2t2FJw4GREXEf2f0zE7qR08zM+inXZtdm6z/8K7LWV10DnJd7/gvgbkmryc70deUM5ktkBeijwLyIeFfSArLLVVamG+9fA2Y12khEbJZ0CbCY7CzrHyPi7gL73zdd7lNzc0RcT/Zapkj6EfAq8NU0/0yy+1GGkl02dFZqPx34uaTLgfeAUxrscwRZvw1JWS8qkNPMzKwtrs2uzdYPKKKr39ibWRVI2hoRw8vOYWZmZhnXZuvPfImsmZmZmZmZNYW/wTQzMzMzM7Om8DeYZmZmZmZm1hQ+wDQzMzMzM7Om8AGmmZmZmZmZNYUPMM3MzMzMzKwpfIBpZmZmZmZmTeEDTDMzMzMzM2uK/wGSp23QXBJlfwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Problem 8\n",
        "y=np.array(np.linspace(start= -20, stop= 20, num= 401, axis=0)).reshape(-1,1)\n",
        "j=np.linspace(start= 1, stop= 50, num= 50, axis=0)\n",
        "X=y**j\n",
        "#X[400]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h43mmIvaDJ3",
        "outputId": "b057a3f6-3e05-43bb-b9ec-f3574181d763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.00000000e+01,  4.00000000e+02, -8.00000000e+03, ...,\n",
              "         2.81474977e+62, -5.62949953e+63,  1.12589991e+65],\n",
              "       [-1.99000000e+01,  3.96010000e+02, -7.88059900e+03, ...,\n",
              "         2.21282805e+62, -4.40352782e+63,  8.76302035e+64],\n",
              "       [-1.98000000e+01,  3.92040000e+02, -7.76239200e+03, ...,\n",
              "         1.73751728e+62, -3.44028422e+63,  6.81176275e+64],\n",
              "       ...,\n",
              "       [ 1.98000000e+01,  3.92040000e+02,  7.76239200e+03, ...,\n",
              "         1.73751728e+62,  3.44028422e+63,  6.81176275e+64],\n",
              "       [ 1.99000000e+01,  3.96010000e+02,  7.88059900e+03, ...,\n",
              "         2.21282805e+62,  4.40352782e+63,  8.76302035e+64],\n",
              "       [ 2.00000000e+01,  4.00000000e+02,  8.00000000e+03, ...,\n",
              "         2.81474977e+62,  5.62949953e+63,  1.12589991e+65]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}