{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrillTime#1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEWnRm0pKZ9hKVv5B5kUuB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elfkr7/Intro-to-DL/blob/main/StrideTricks%26GradientDescentTypes_Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EavYiHx0628q"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.ones((7,7), dtype='int32')\n",
        "for i in range(0, 7):\n",
        "  for j in range(0,7):\n",
        "    X[j,i] = i\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL-MbrOh84Zb",
        "outputId": "7a073f49-68e7-4926-b46c-ca298b58e211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 2, 3, 4, 5, 6],\n",
              "       [0, 1, 2, 3, 4, 5, 6],\n",
              "       [0, 1, 2, 3, 4, 5, 6],\n",
              "       [0, 1, 2, 3, 4, 5, 6],\n",
              "       [0, 1, 2, 3, 4, 5, 6],\n",
              "       [0, 1, 2, 3, 4, 5, 6],\n",
              "       [0, 1, 2, 3, 4, 5, 6]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([2,3,5,7,11,13,17,19,23],dtype= 'int32')\n",
        "np.lib.stride_tricks.as_strided(A, shape=(7,3), strides=(4,4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDooLoJ284xo",
        "outputId": "291d37c5-5338-4c39-a81d-954888fb0af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  3,  5],\n",
              "       [ 3,  5,  7],\n",
              "       [ 5,  7, 11],\n",
              "       [ 7, 11, 13],\n",
              "       [11, 13, 17],\n",
              "       [13, 17, 19],\n",
              "       [17, 19, 23]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD updates the parameter for a single data sample whereas standard gradient descent needs to evaluate the entire dataset to update parameters in each iteration. Since SGD updates the parameter based on the random single data points in each iteration, definitely saves the computation time. However this time, each update with a high variation can cause big jumps, and fluctuations happen. This means accuracy might not be the best compared to the standard gradient descent since SGD can end up in a different local minimum that might not minimize the error at most. We have a better model than gradient descent in terms of computation time and better than SGD in terms of accuracy and variation, which is mini-batch gradient descent. The challenge this time is the need to specify the batch size. But in general, mini-batch gradient descent would be the moderate choice."
      ],
      "metadata": {
        "id": "yMAor6Q0hMBq"
      }
    }
  ]
}